---
permalink: /
title: "Yann Teytaut"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a PhD candidate in sound/music processing and deep learning applied to singing and speech. I work at [Ircam](https://www.ircam.fr/) (Institute for Research and Coordination in Acoustics/Music) as part of the [Sound Analysis/Synthesis](http://anasynth.ircam.fr/home/) team. My work interests are mainly focused on voice alignment and singing style analysis for both research and musicological applications. See the [**ARS**](https://ars.ircam.fr/) (**A**nalysis and t**R**ansformation of **S**inging style) project webpage.

I'm also teaching tutorials, practical works and a few lectures in computer science and sound signal processing at [Polytech Sorbonne](https://www.polytech.sorbonne-universite.fr/) and [Sorbonne Université](https://www.sorbonne-universite.fr/).

I graduated with a M.Res. in Acoustics, Signal processing and Informatics Applied to Music ([ATIAM](https:/www.atiam.ircam.fr)) from [Sorbonne Université](https://www.sorbonne-universite.fr/) in 2019, a M.Eng. in Optical computing and image processing from the [Institut d'Optique Graduate School](https://www.institutoptique.fr/) and a M.Sc. in Computer science for image and sound from [Bordeaux Université](https://www.u-bordeaux.fr/) in 2018.

